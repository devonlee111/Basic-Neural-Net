This file contains some information on settings that worked for testing my neural net, "MLP.py", using the xOR function as the training data.
The files used for the training/testing are located at datafiles/tanhTestData and datafiles/SigmoidTestData.


All testing was done to an average error of .05


activation function: 	sigmoid
datafile:		SigmoidTestData

-s (stochastic)
lr = .1
shape = 2 3 1
epoch = 89411

-b (batch)
lr = .1
shape = 2 3 1
epoch = 120103


activation function:	tanh
datafile:		tanhTestData

-s (stochastic)
lr = .01
shape = 2 3 1
epoch = 128068

-b (batch)
lr = .1
shape = 2 3 1
epoch = 657


activation function:	ReLU
datafile:		SigmoidTestData

-s (stochastic)
lr = .0001
shape = 2 256 1
epoch = 315231

-b (batch)
lr = .001
shape = 2 256 1
epoch = 7424


activation function:	LReLU
datafile:		sigmoidTestData

-s (stochastic)
lr =.001
shape = 2 256 1
epoch = 282785

-b (batch)
lr = .01
shape = 2 256 1
epoch = 7833
